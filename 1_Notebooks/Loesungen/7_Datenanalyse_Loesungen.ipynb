{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d9baad-a423-4ae2-a7bf-d2b73f848ffc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Datenanalyse (L√∂sungen)\n",
    "\n",
    "‚òùÔ∏è Beachte: es gibt beim Programmieren fast immer verschiedene L√∂sungswege. Deine L√∂sung mag anders aussehen, aber dennoch zum gew√ºnschten Resultat f√ºhren. Das richtige Resultat ist das Wichtigste. \n",
    "\n",
    "‚ö†Ô∏è F√ºhre folgenden Code aus, bevor du einzelne L√∂sungen ausf√ºhrst. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e03a4-b7bb-400b-b101-383ef481d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt \n",
    "with open(\"../../3_Dateien/Songkorpus/songkorpus_token.tsv\") as f:\n",
    "    songkorpus = pd.read_csv(f, sep=\"\\t\")\n",
    "    \n",
    "songkorpus.columns = [\"Token\", \"Jahr\", \"H√§ufigkeit\"]\n",
    "\n",
    "tokens = songkorpus[\"Token\"]\n",
    "\n",
    "decades = []\n",
    "for year in (songkorpus[\"Jahr\"]):\n",
    "    decade = str(year)[:-1] + \"0\"\n",
    "    decades.append(decade)\n",
    "    \n",
    "songkorpus[\"Dekade\"] = decades\n",
    "original_len = len(songkorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22170b-c5be-4da7-91d7-ce4381124664",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 1:** Lass Dir das 100.000te, 200.000te und 300.000te Token in der Series `tokens` ausgeben. Verwende dazu maximal eine Zeile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcc6a6-ad19-48f9-ae3b-22227cb7c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens[[100000,200000,300000]]) #Alternative 1: Liste an Indizes (beachte die inneren eckigen Klammern!)\n",
    "print(tokens[100000::100000]) #Alternative 2: Slicing mit Start-Index 100000 und Step 100000, vgl. zweites Notebook\n",
    "print(tokens[100000], tokens[200000], tokens[300000]) #Alternative 3 (ein bisschen langweiliger als die oberen üòÖ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5b42a-3e16-43c2-be74-4ac38f3b8987",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 2:** \n",
    "\n",
    "1. Lies die Datei `songkorpus_tokens.tsv` abermals ein und √ºbergib beim Erstellen des DataFrames zus√§tzlich den Parameter `index_col=0`. Dadurch wird die erste Spalte (mit dem Index 0), also diejenige mit den Tokens, zur sog. *Index-Spalte*. Jede Zeile hat nun statt einem numerischen Index einen Namen, n√§mlich das jeweilige Token. Weise das DataFrame der Variablen `songkorpus_labelled_rows` zu. \n",
    "2. Benenne die Spalten wie bei `songkorpus` um. Falls Du hier eine Fehlermeldung kriegst, lies sie aufmerksam und passe Deinen Code entsprechend an.\n",
    "3. √úberlege Dir, was die Tatsache, dass wir nun Tokens als Zeilennamen verwenden, zur Konsequenz hat. Experimentiere dazu gerne mit dem DataFrame herum und greife auf verschiedene Zeilen √ºber Namen zu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344fa88-b369-4be1-881c-c5ff50787505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt \n",
    "with open(\"../../3_Dateien/Songkorpus/songkorpus_token.tsv\") as f:\n",
    "    songkorpus_labelled_rows = pd.read_csv(f, sep=\"\\t\", index_col=0) \n",
    "    \n",
    "songkorpus_labelled_rows.columns = [\"Jahr\", \"H√§ufigkeit\"] \n",
    "\n",
    "#Zu 3.: Zeilennamen k√∂nnen mehrfach vorkommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e86b4-202f-42fc-9010-fc64aafec336",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 3:** Setze die Tatsache, dass Zeilennamen mehrfach vorkommen d√ºrfen, produktiv ein und finde heraus, wie oft \"Dresden\" in `songkorpus_labelled_rows` vorkommt, indem Du die H√§ufigkeiten in allen Jahren, in denen das Wort gesungen wird, zusammenz√§hlst.\n",
    "\n",
    "üí° Tipp: Der erste Schritt besteht darin, aus dem gesamten DataFrame `songkorpus_labelled_rows` ein kleineres sog. *Sub-DataFrame* zu erstellen, das mit einer neuen Variablen referenziert wird. Der zweite Schritt besteht darin, eine Series aus diesem Sub-DataFrame \"herauszuschneiden\", die Du anschlie√üend wie eine Liste behandeln kannst, um schlie√ülich zur Anzahl der Nennungen von \"Dresden\" zu gelangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de3f1d-17ec-4ba7-a4b9-5cf9af7fe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dresden = songkorpus_labelled_rows.loc[\"Dresden\"] #erst greifen wir auf alle Zeilen zu, die \"Dresden\" als Label haben und weisen das Resultat der Variablen \"dresden\" zu\n",
    "occurrences_per_year = dresden[\"H√§ufigkeit\"] #anschlie√üend greifen wir auf die Spalte \"H√§ufigkeit\" im Sub-DataFrame \"dresden\" zu und weisen die resultierende Series der Variablen \"occurrences_per_year\" zu\n",
    "\n",
    "#nun iterieren wir √ºber \"occurrences_per_year\" wie bei einer Liste und erh√∂hen die Z√§hlvariable \"total\" um den jeweiligen Zeilenwert\n",
    "total = 0\n",
    "for year in occurrences_per_year:\n",
    "    total += year\n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711ea39-898d-4ae4-904d-18baca47f0ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 4:** F√ºge `songkorpus` eine weitere Spalte mit dem Namen \"L√§nge\" hinzu, in der die Anzahl Buchstaben je Token steht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50a8d7-ab0b-46bd-bd3b-273ab8ee4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for token in songkorpus[\"Token\"]:\n",
    "    length = len(str(token)) #Casten in string ist n√∂tig, da manche Tokens Zahlen sind und Zahlen keine L√§nge haben, vgl. zweites Notebook\n",
    "    lengths.append(length)\n",
    "    \n",
    "songkorpus[\"L√§nge\"] = lengths\n",
    "\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683ed31-2a41-4d3c-8001-dcc6af6ec194",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 5:** Vereinfache den Code von oben, mit dessen Hilfe wir die Spalte \"Dekade\" hinzugef√ºgt haben, indem Du ihn mittels List Comprehension (vgl. viertes Notebook) auf eine einzige Zeile reduzierst. Hole den Abschnitt zu List Comprehensions nach, falls Du ihn damals ausgelassen hast, da er als fortgeschritten markiert war.\n",
    "\n",
    "Hinweis: `songkorpus` verf√ºgt ja bereits √ºber eine Spalte mit der Bezeichnung \"Dekade\". Indem Du das Resultat Deiner List Comprehension `songkorpus[\"Dekade\"]` zuweist, √ºberschreibst du die befindliche Spalte ganz einfach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b035b44-6ad4-4224-837a-4feacd47b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Dekade\"] = [str(year)[:-1] + \"0\" for year in songkorpus[\"Jahr\"]]\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d1ac0-f71c-4606-b82c-1f68d673a736",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 6:** F√ºhre die Zelle oben, in der wir `songkorpus` Zeilen mit Fantasiew√∂rtern hinzugef√ºgt haben, noch ein paar Mal aus, ohne darauf zu achten wie oft. Verwende nun `drop` in einer geeigneten Kontrollstruktur (vgl. drittes Notebook) sowie die anfangs eingef√ºhrte Variable `original_len`, um die Fantasiew√∂rter wieder zu entfernen und `songkorpus`, was die Anzahl an Zeilen betrifft, wieder in seinen Originalzustand zu bringen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7d2bf-aedc-4559-b9de-802ebc57ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vorbereitung, die im Lehrnotebook nicht notwendig ist: \n",
    "#Wir f√ºngen \"new_row\", sagen wir, 17 Mal \"songkorpus\" hinzu\n",
    "new_row = [\"Fantasiewort\", 2023, 800, 2020, 12]\n",
    "for i in range(17):\n",
    "    songkorpus.loc[len(songkorpus)] = new_row\n",
    "\n",
    "#hier beginnt die L√∂sung:\n",
    "#was im Schleifenk√∂rper steht, wird wiederholt ausgef√ºhrt, bis die L√§nge von \"songkorpus\"\n",
    "#kleiner als die urspr√ºngliche L√§nge ist, d.h. wir h√∂ren auf, wenn beide Werte gleich viel betragen\n",
    "while len(songkorpus) > original_len:\n",
    "    #als Index setzen wir die L√§nge von \"songkorpus\" minus 1 ein; minus 1, da Indizes bei 0 beginnen\n",
    "    songkorpus.drop(len(songkorpus)-1, inplace=True)\n",
    "\n",
    "#hier √ºberpr√ºfen wir das Resultat\n",
    "songkorpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656866b-407e-4065-8e22-4d4615b6ac52",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 7:** Mithilfe von `describe` haben wir oben herausgefunden, dass die durchschnittliche Wortl√§nge in `songkorpus` 6.88 Buchstaben betr√§gt. Die maximale Wortl√§nge betr√§gt hingegen sagenhafte 53 Buchstaben. Die Verteilung scheint alles andere als gleichm√§√üig zu sein, was wir auch an den sog. *Quartilen* 25% und 75% sehen (Quartile werden wie der Median berechnet, nur geht es nicht um den Mittelwert sondern um die Werte nach einem Viertel bzw. drei Vierteln aller aufgereihten Werte). Finde heraus, welche Wortl√§ngen f√ºr jeweils mindestens 10 % aller W√∂rter gelten. Finde ebenfalls heraus, welche Wortl√§ngen f√ºr jeweils maximal 1 % aller W√∂rter gelten.\n",
    "\n",
    "üí° Tipp: Einer von verschiedenen denkbaren L√∂sungswegen involviert die Tatsache, dass DataFrames und Series mit dictionaries verwandt sind und sich auch in ein solches casten lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a247969-c66f-4350-91b0-43568955a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = dict(songkorpus[\"L√§nge\"].value_counts(normalize=True))\n",
    "\n",
    "min_10_pc = [] \n",
    "max_1_pc = []\n",
    "\n",
    "for key, value in lengths.items():\n",
    "    if value > 0.1:\n",
    "        min_10_pc.append(str(key))\n",
    "    elif value < 0.01:\n",
    "        max_1_pc.append(str(key))\n",
    "\n",
    "print(\"Mind. 10 %:\", \", \".join(min_10_pc), \"\\nMax. 1 %:\", \", \".join(max_1_pc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41973d7c-514c-4e53-bfd4-baed558e640e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a832d86-43cb-4cfe-a116-910d0b5762d7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "‚úèÔ∏è **L√∂sung 8:** Wir wissen bereits, wieviele Tokens in unserem DataFrame vorkommen, n√§mlich 386.510. Finde heraus, wieviele einzigartige Token, also Types (vgl. viertes Notebook) es gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd12a9-ebc2-49b0-bbf7-091913dbb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(songkorpus[\"Token\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe22d34-73ee-43a6-9023-6373280b5b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exdimed",
   "language": "python",
   "name": "exdimed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}